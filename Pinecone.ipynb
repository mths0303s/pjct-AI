{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0d2341-e723-405b-a1db-8170149ca8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import docx\n",
    "import openai\n",
    "import pinecone\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from getpass import getpass\n",
    "\n",
    "openai.api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe8af11-12dc-4b1a-8806-bb90908360f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = \"book\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7380ef4a-d2a4-479a-8073-9143ffd7b1f7",
   "metadata": {},
   "source": [
    "## Parse document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8175ff71-e665-4410-becf-bad65f58d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "for f_name in os.listdir(docs_path):\n",
    "    doc_path = os.path.join(docs_path, f_name)\n",
    "    doc = docx.Document(doc_path)\n",
    "    for p in doc.paragraphs:\n",
    "        text_chunks.append(p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c317bbd7-ee71-47b3-befe-f9886dcf4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all chunks shorter than 10 words and strip the rest\n",
    "text_chunks = [string.strip().strip('\\n') for string in text_chunks if len(string.split()) >= 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c01905-ce0b-47a3-b4bc-6ed1f0bc08e4",
   "metadata": {},
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec93825d-de94-4609-ab49-2b507ce68547",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_with_embeddings = []\n",
    "for chunk in text_chunks:\n",
    "    embedding = get_embedding(chunk, engine=\"text-embedding-ada-002\")\n",
    "    chunks_with_embeddings.append({\"text\": chunk, \"embedding\": embedding})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fbaa6-cf67-41f4-950a-0acf272d3f07",
   "metadata": {},
   "source": [
    "## Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f7eeaf7-b68b-4019-8fcf-5dd74480efa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(\n",
    "    api_key = getpass(),\n",
    "    environment=\"us-central1-gcp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f9583f-3124-49e5-be4a-9a86aef76b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "index_name = \"livro-python\"\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=1536)\n",
    "    \n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5df67b33-373c-47b5-9895-4c78b7950ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process everything in batches of 64\n",
    "batch_size = 64\n",
    "\n",
    "for i in range(0, len(chunks_with_embeddings), batch_size):\n",
    "    data_batch = chunks_with_embeddings[i: i+batch_size]\n",
    "    \n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(chunks_with_embeddings))\n",
    "    \n",
    "    # get batch meta\n",
    "    text_batch = [item[\"text\"] for item in data_batch]\n",
    "    \n",
    "    # get ids\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    \n",
    "    # get embeddings\n",
    "    embeds = [item[\"embedding\"] for item in data_batch]\n",
    "    \n",
    "    # prepare metadata and upsert batch\n",
    "    meta = [{\"text\": text_batch} for text_batch in zip(text_batch)]\n",
    "    to_upsert = zip(ids_batch, embeds, meta)\n",
    "    \n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17874cd-72e5-4176-ad30-eae717913f96",
   "metadata": {},
   "source": [
    "## Query Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2692829a-8fc1-49a7-a6b9-b30d6faa4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_docs(query):\n",
    "    xq = openai.Embedding.create(input=query, engine=\"text-embedding-ada-002\")[\"data\"][0][\"embedding\"]\n",
    "    res = index.query([xq], top_k=5, include_metadata=True)\n",
    "    chosen_text = []\n",
    "    for match in res[\"matches\"]:\n",
    "        chosen_text = match[\"metadata\"]\n",
    "    return res[\"matches\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f18631cb-1d1e-45a0-98ed-76ea6aa3a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92: {'text': ['A função raw_input do Python2 foi renomeada para input() no Python3:']}\n",
      "0.86: {'text': ['O Python possui uma função que captura a entrada de valores: a função input() . Quando essa função é chamada, o programa para e espera o usuário digitar alguma coisa. Quando o usuário aperta a tecla ENTER , o programa processa e imprime o valor digitado em forma de string:']}\n",
      "0.84: {'text': ['Existem casos que exigem o Python2 ao invés do Python3 como implementar algo em um ambiente que o programador não controla ou quando precisa utilizar algum pacote/módulo específico que não possui versão compatível com Python3. Vale ressaltar para quem deseja utilizar uma implementação alternativa do Python, como o IronPython ou Jython, que o suporte ao Python3 ainda é bastante limitado.']}\n",
      "0.83: {'text': ['Para que várias ferramentas disponíveis na versão 3 funcionem na versão 2, ou seja, o módulo __future__   permite usar funcionalidades do Python3 no Python2. Mas cuidado, algumas funcionalidades  são  sobrescritas  e  é  importante  sempre  checar  a  documentação:']}\n",
      "0.83: {'text': ['Atualmente existe a ferramenta 2to3 que permite que código Python3 seja gerado a partir de código Python2. Há também a ferramenta 3to2, que visa converter o código Python3 de volta ao código Python2. No entanto, é improvável que o código que faz uso intenso de recursos do Python3 seja convertido com sucesso.']}\n"
     ]
    }
   ],
   "source": [
    "matches = search_docs(\"A função raw_input do Python2 funciona no Python3 ?\")\n",
    "for match in matches:\n",
    "    print(f\"{match['score']:.2f}: {match['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854af05-10a2-472e-9a6c-438ad028d2c0",
   "metadata": {},
   "source": [
    "## Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b9167aab-8e99-4fdb-98af-00d73c026379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(query):\n",
    "    matches = search_docs(query)\n",
    "    \n",
    "    chosen_text = []\n",
    "    for match in matches:\n",
    "        chosen_text.append(match[\"metadata\"][\"text\"])\n",
    "        \n",
    "    prompt = \"\"\"Responda à pergunta com a maior sinceridade possível usando o contexto abaixo e,\n",
    "                se a resposta não for dentro do contexto, diga apenas: eu não sei.\"\"\"\n",
    "    prompt += \"\\n\\n\"\n",
    "    prompt += \"Contexto: \" + \"\\n\".join(str(text) for text in chosen_text)\n",
    "    prompt += \"\\n\\n\"\n",
    "    prompt += \"Pergunta: \" + query\n",
    "    prompt += \"\\n\"\n",
    "    prompt += \"Resposta: \"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "744feeb9-b5ad-4777-9209-397b08f04bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(query):\n",
    "    prompt = construct_prompt(query)\n",
    "    res = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        model=\"text-davinci-003\",\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    return res.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d538190c-406e-4fe3-a1d9-b825f5076b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Não, a função raw_input do Python2 foi renomeada para input() no Python3.\n"
     ]
    }
   ],
   "source": [
    "print(answer_question(\"A função raw_input do Python2 funciona no Python3 ?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
